{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import utils as u\n",
    "\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data'\n",
    "MODEL_PATH = 'model'\n",
    "MODEL_CHECKPOINT = \"nvidia/mit-b2\"\n",
    "NAME = f'Segformer'\n",
    "\n",
    "IMG_SIZE = 256\n",
    "N_CHANNELS = 3\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "SEED = 5\n",
    "K_FOLDS = 5\n",
    "TRAIN_SPLIT = 0.95\n",
    "DATA_LIMIT = None\n",
    "\n",
    "LR = 1e-4\n",
    "LR_ADJ = 'None'\n",
    "EPOCHS = 100\n",
    "\n",
    "PATIENCE = 15\n",
    "DELTA = 0.01\n",
    "\n",
    "hyperparams = {\n",
    "    \"MODEL_CHECKPOINT\": MODEL_CHECKPOINT,\n",
    "    \"NAME\": NAME,\n",
    "    \"IMG_SIZE\": IMG_SIZE,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"SEED\": SEED,\n",
    "    \"TRAIN_SPLIT\": TRAIN_SPLIT,\n",
    "    \"DATA_LIMIT\": DATA_LIMIT,\n",
    "    \"LR\": LR,\n",
    "    \"LR_ADJ\": LR_ADJ,\n",
    "    \"EPOCHS\": EPOCHS,\n",
    "    \"PATIENCE\": PATIENCE,\n",
    "    \"DELTA\": DELTA\n",
    "}\n",
    "\n",
    "json_path = f\"{MODEL_PATH}/{NAME}/hyperparameters.json\"\n",
    "os.makedirs(f\"{MODEL_PATH}/{NAME}\", exist_ok=True)\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(hyperparams, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = u.get_image_path(f'{DATA_PATH}/train_val', limit=DATA_LIMIT, seed=SEED)\n",
    "train_dataset, val_dataset = train_test_split(dataset, train_size=TRAIN_SPLIT, random_state=SEED, shuffle=True)\n",
    "\n",
    "train_loader= DataLoader(u.LandsatDataset(dataset=train_dataset, size=IMG_SIZE, do_augmentation=True), shuffle=True, batch_size=BATCH_SIZE, drop_last=True, num_workers=8)\n",
    "val_loader= DataLoader(u.LandsatDataset(dataset=val_dataset, size=IMG_SIZE, do_augmentation=False), shuffle=False, batch_size=BATCH_SIZE, drop_last=True, num_workers=8)\n",
    "\n",
    "print(f\"Dataset size: \\t{len(dataset)}\")\n",
    "print(f\"Training: \\t#{len(train_dataset)} (samples)\\t#{len(train_loader)} (batchs)\")\n",
    "print(f\"Validation: \\t#{len(val_dataset)} (samples)\\t#{len(val_loader)} (batchs)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = u.get_image_path(f'{DATA_PATH}/train_val', limit=DATA_LIMIT, seed=SEED)\n",
    "# kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "#     print(f\"Fold {fold+1}/{K_FOLDS}\")\n",
    "\n",
    "#     train_dataset = [dataset[i] for i in train_idx]\n",
    "#     val_dataset = [dataset[i] for i in val_idx]\n",
    "#     break\n",
    "\n",
    "# train_loader= DataLoader(u.LandsatDataset(dataset=train_dataset, size=IMG_SIZE, do_augmentation=True), shuffle=True, batch_size=BATCH_SIZE, drop_last=True, num_workers=4, prefetch_factor=8)\n",
    "# val_loader= DataLoader(u.LandsatDataset(dataset=val_dataset, size=IMG_SIZE, do_augmentation=False), shuffle=False, batch_size=BATCH_SIZE, drop_last=True, num_workers=4, prefetch_factor=8)\n",
    "\n",
    "# print(f\"Dataset size: \\t{len(dataset)}\")\n",
    "# print(f\"Training: \\t#{len(train_dataset)} (samples)\\t#{len(train_loader)} (batchs)\")\n",
    "# print(f\"Validation: \\t#{len(val_dataset)} (samples)\\t#{len(val_loader)} (batchs)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u.plotter(train_loader)\n",
    "# u.plotter(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: 'background', 1: 'fire'}\n",
    "label2id = {label: id for id, label in id2label.items()}\n",
    "num_labels = len(id2label)\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.config.image_size = IMG_SIZE\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.decode_head.parameters():\n",
    "    param.requires_grad = True\n",
    "model.decode_head.classifier = torch.nn.Conv2d(768, num_labels, kernel_size=(1, 1))\n",
    "\n",
    "summary(model=model, \n",
    "        input_size=(BATCH_SIZE, N_CHANNELS, IMG_SIZE, IMG_SIZE), # (batch_size, color_channels, height, width)\n",
    "        col_names=[\"input_size\", \"output_size\", \"trainable\"],\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss() # to be changed \n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR) # lr to be changed \n",
    "u.seed_everything(SEED)\n",
    "u.train_and_validate(\n",
    "    name=NAME,\n",
    "    model=model.cuda(),\n",
    "    train_=train_loader,\n",
    "    val_=val_loader,\n",
    "    loss_=loss,\n",
    "    optimizer=optimizer,\n",
    "    scheduler_type=LR_ADJ,\n",
    "    epochs=EPOCHS,\n",
    "    delta=DELTA,\n",
    "    early_stop=PATIENCE,\n",
    "    output_dir=MODEL_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = u.get_image_path(f'{DATA_PATH}/test', seed=SEED)\n",
    "test_loader= DataLoader(u.LandsatDataset(dataset=test_dataset, size=IMG_SIZE, do_augmentation=False), shuffle=False, batch_size=10)\n",
    "print(f\"Test: #{len(test_dataset)} (samples)\\t#{len(test_loader)} (batchs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    f'D:\\DATA-5000\\model\\{NAME}'\n",
    ").cuda()\n",
    "img, gt, pr, path = u.test(NAME, model, test_loader, MODEL_PATH, th=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.plotter_results(images=img, masks=gt, predictions=pr, path=path, num_samples= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.plotter_history(f'model\\{NAME}\\history.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
